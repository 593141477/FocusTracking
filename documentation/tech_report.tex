\documentclass[12pt]{article}

%设置页边距
\usepackage{geometry}
\geometry{left=2.5cm,right=2.5cm,top=2.5cm,bottom=2.5cm}

%地址链接支持
\usepackage{hyperref}

%支持分栏
\usepackage{multicol}

%页眉页脚
\usepackage{fancyhdr}
\pagestyle{fancy}
\lhead{项目技术报告}
\rhead{Technical Report}

%设置字体
\usepackage[no-math]{fontspec}
\usepackage{xunicode}
\usepackage{xltxtra}
\setmainfont[AutoFakeSlant]{Hiragino Sans GB W3}

%设置换行缩进
\usepackage[indentfirst=false,slantfont,boldfont]{xeCJK}
\usepackage{indentfirst}
\setlength{\parindent}{0.9cm}

%行距
\linespread{1.2}

\begin{document}

\title{技术报告：\\[3ex] 基于主页标题文字的\\热点新闻跟踪与分析、可视化展示\\[3ex]}

\author{开发小组}

\date{2014年6月}
\maketitle
\newpage
\renewcommand{\contentsname}{技术报告}
\tableofcontents
\newpage
\section{需求分析}
目前新闻网站内部的新闻有比较好的分类，可以比较容易的收集关于同一个事件的相关新闻。但是收集不同门户网站的相关新闻就显得比较困难。而用户希望得到多个网站相关的新闻信息。所以将门户网站的新闻进行聚类整理就显得十分重要。

同时，如果不同门户网站同时出现了相关新闻，也能反映出当前社会的热点。对门户网站新闻进行聚类也有利于社会热点的研究，如果有大量历史数据的数据库，则在社会研究上也有较好的附加效益。

\section{模块介绍}
实现这些功能需要的步骤如下：
\begin{itemize}
\item 从各种门户网站抓取标题数据
\item 在数据库存储有关数据
\item 用户提交查询的需求
\item 算法对相关标题数据进行聚类
\item 将结果在界面上展示
\end{itemize}

\subsection{网页抓取}
本部分集成了html和json解析,能够适应大部分的web页面和ajax请求数据解析,尽可能多的支持各个新闻网站.
所有Spider继承自SpiderBase,并可选继承GumboBasedSpider或JsonBasedSpider以获取HTML及JSON解析功能.

主要类的设计如下:

\begin{itemize}
\item SpiderBase\\
所有Spider的基类,提供网页抓取的基础功能(如HTTP请求,编码转换)

\item GumboBasedSpider\\
提供基于第三方库gumbo的html dom树解析,类中声明了两个纯虚的回调函数,留给子类实现,以适应不同网站的不同网页结构.
其中searchNodeCallback在递归遍历dom节点时调用,由子类判断节点是否有用,是否需要深入遍历;resultCallback在遍历先前存储的节点时,有子类进一步过滤出需要保留的信息.

\item JsonBasedSpider\\
提供对于json格式数据的解析,基于第三方库JSON++.

\item SpiderFor163,SpiderForQQ,SpiderForSina\\
具体Spider实现,提供对于相应门户网站新闻主页的抓取

\item SpiderFor163,SpiderForSinaRoll,SpiderForQQRoll\\
具体Spider实现,提供对于相应门户网站滚动新闻的抓取

\end{itemize}
%=======================subsection end===========================

\subsection{数据存储}

为了提供历史新闻跟踪分析功能,需要存储历史抓取数据,因此设计了数据存储部分.为了快速查找,这部分使用数据库作为后端存储.目前选用的轻量级的关系型数据库sqlite.

主要类的设计如下:

\begin{itemize}
\item StorageBase\\
提供与数据库引擎无关的数据操作接口,使主程序与数据库解耦.目前,仅实现了插入和按日期查找的接口.

\item SqliteDatabaseStorage\\
继承自StorageBase,实现接口数据类型向sqlite数据库的类型转换,以及sql语句构造等功能.
\end{itemize}

%=======================subsection end===========================

\subsection{核心算法}
核心算法部分涉及include/tracker/和src/tracker/目录下的所有文件。为了方便中文处理，核心算法部分全部使用C++11中的u32string。
\begin{itemize}
\item title.h 声明了标题类title和聚类标题集titlebundle，用于与外部通信。
\item tracker.h 声明了聚类器的基类tracker，其中trackFocus的纯虚函数以vector<title>作为输入，以vector<titlebundle>作为输出。
\item trackerForce.h, trackerForce.cpp 声明并定义了一个基于单个字的聚类器trackerForce，继承自tracker。
\item trackerCluster.h, trackerCluster.cpp 声明并定义了一个基于分词和K-means算法的分类器trackerCluster，继承自tracker。
\item trie.h 声明并定义了一个字典树的模板trie，trie<u32string>在trackerCluster中被使用。
\item segment.h segment.cpp 声明并定义了一个基于双向最大匹配的分词算法，在trackerCluster中被使用，输入是u32string，输出是vector<u32string>。

\end{itemize}
%=======================subsection end===========================

\subsection{用户交互}

UI部分采用HTML+JS方式开发,并在程序中使用libmicrohttpd提供内置http服务器.

前端采用jQuery框架,并使用jquery.awesomeCloud插件显示词云.

%=======================subsection end===========================

\section{目录结构}
\noindent
├── 3rdparty   第三方库目录\\
│\verb|   |├── JSON++\\
│\verb|   |└── gumbo-parser\\
├── bin   目标文件\\
├── documentation  文档目录\\
├── include  所有头文件\\
│\verb|   |├── spider\\
│\verb|   |├── storage\\
│\verb|   |├── tracker\\
│\verb|   |└── web\\
├── scripts  工具脚本\\
├── src  源码目录\\
│\verb|   |├── spider  爬虫部分\\
│\verb|   |├── storage   存储部分\\
│\verb|   |├── tracker  核心算法\\
│\verb|   |└── web  网页服务器\\
├── testdata  算法测试数据\\
└── tests  单元测试程序\\


\section{编译方法}

在Mac OS X系统下,安装如下依赖包: 

brew install curl libmicrohttpd pcre sqlite cmake autoconf automake bison flex libtool pkg-config\\

进入顶层目录编译:

make

%=======================section    end===========================

\end{document}